[{"body":"private   batchindices   —   function Get the indices of batch  i  with batch size  size  of a collection with  n  elements . Might be a partial batch if  i  is the last batch and n  is not divisible by  size .","id":"docstrings/DataLoaders.batchindices.html"},{"body":"private   obsslices   —   function Iterate over views of all observations in a  batch . batch  can be a batched array, a tuple of batches, or a dict of batches .","id":"docstrings/DataLoaders.obsslices.html"},{"body":"public   eachobsparallel   —   function Parallel data iterator for data container  data .  Loads data on all available threads (except the first if  useprimary  is  false ) . If  buffered  is  true , uses  getobs!  to load samples inplace . See also  MLDataPattern.eachobs eachobsparallel  does not guarantee that the samples are returned in the correct order .","id":"docstrings/DataLoaders.eachobsparallel.html"},{"body":"DataLoaders . jl Documentation (latest) A Julia package implementing performant data loading for deep learning on out - of - memory datasets that .  Works like PyTorch ’ s  DataLoader .","id":"README.html#dataloadersjl"},{"body":"private   BatchViewCollated   —   parametric type A batch view of container  data  with collated batches of size  size .","id":"docstrings/DataLoaders.BatchViewCollated.html"},{"body":"private   collate   —   function Collates a vector of samples into a single batch .  See  collating .","id":"docstrings/DataLoaders.collate.html"},{"body":"When should you use it? You have a dataset that does not fit into memory You want to reduce the time your training loop is waiting for the next batch of data","id":"README.html#when-should-you-use-it"},{"body":"private   RingBuffer   —   parametric type A  Channel - like data structure that rotates through size  buffers .   put! s work by mutating one of the buffers: The result can then be  take! n: Only one result is valid at a time !  On the next  take! , the previous result will be reused as a buffer and be mutated by a  put!","id":"docstrings/DataLoaders.RingBuffer.html"},{"body":"Arguments Positional data : A data container supporting the  LearnBase  data access pattern batchsize = 1 : Number of samples to batch together .  Disable batching by setting to  nothing . Keyword partial::Bool = true : Whether to include the last batch when  nobs(dataset)  is not divisible by  batchsize .   true  ensures all batches have the same size, but some samples might be dropped . buffered::Bool = collate : If  buffered  is  true , loads data inplace using  getobs! .  See  Data containers  for details on buffered loading . parallel::Bool = Threads.nthreads() > 1) : Whether to load data in parallel, keeping the primary thread is .  Default is  true  if more than one thread is available . useprimary::Bool = false : If  false , keep the main thread free when loading data in parallel .  Is ignored if  parallel  is  false .","id":"docstrings/DataLoaders.DataLoader.html#arguments"},{"body":"How do you use it? Install like any other Julia package using the package manager (see  setup ): After installation, import it, create a  DataLoader  from a dataset and batch size, and iterate over it:","id":"README.html#how-do-you-use-it"},{"body":"public   DataLoader   —   function Create an efficient iterator of batches over  data container   data .","id":"docstrings/DataLoaders.DataLoader.html"},{"body":"public   put!   —   function Apply f !  to a buffer in  ringbuffer  and put into the results channel .","id":"docstrings/Base.put!.html"},{"body":"What does it do? Uses multi - threading to load data in parallel while keeping the primary thread free for the training loop Handles batching and  collating Is simple to  extend  for custom datasets Integrates well with other packages in the  ecosystem Allows for  inplace loading  to reduce memory load","id":"README.html#what-does-it-do"},{"body":"Next, you may want to read What datasets you can use it with How it compares to PyTorch ’ s data loader","id":"README.html#next-you-may-want-to-read"},{"body":"Examples Creating a data loader with batch size 16 and iterating over it: Creating a data loader that  uses buffers  to load batches: Turning off  collating :","id":"docstrings/DataLoaders.DataLoader.html#examples"},{"body":"private   BufferGetObsParallel   —   parametric type Like  MLDataPattern.BufferGetObs  but preloads observations into a buffer ring with multi - threaded workers .","id":"docstrings/DataLoaders.BufferGetObsParallel.html"}]